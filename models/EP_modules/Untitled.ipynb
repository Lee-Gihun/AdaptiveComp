{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ResNet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCAN(nn.Module):\n",
    "    \"\"\"\n",
    "    SCAN\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, channels, stride=(1,1,1), final_channels=512, num_classes=100):\n",
    "        super(SCAN, self).__init__()\n",
    "        \n",
    "        # activation func\n",
    "        self._relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # attention module\n",
    "        self._attconv = nn.Conv2d(channels, channels, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self._attbn0 = nn.BatchNorm2d(channels)\n",
    "        self._attdeconv = nn.ConvTranspose2d(channels, channels, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self._attbn1 = nn.BatchNorm2d(channels)\n",
    "        \n",
    "        # bottleneck module\n",
    "        self._bot1x1_0 = nn.Conv2d(channels, channels, kernel_size=1, stride=stride[0], bias=False)\n",
    "        self._botbn0 = nn.BatchNorm2d(channels)\n",
    "        self._bot3x3 = nn.Conv2d(channels, channels, kernel_size=3, stride=stride[1], padding=1, bias=False)\n",
    "        self._botbn1 = nn.BatchNorm2d(channels)\n",
    "        self._bot1x1_1 = nn.Conv2d(channels, final_channels, kernel_size=1, stride=stride[2], bias=False)\n",
    "        self._botbn2 = nn.BatchNorm2d(final_channels)\n",
    "        \n",
    "        # classifier module\n",
    "        self._globalavgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self._shallow_classifier = nn.Conv2d(final_channels, num_classes, kernel_size=1, stride=1, bias=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # attention\n",
    "        att = self._relu(self._attbn0(self._attconv(x)))\n",
    "\n",
    "        att = self._relu(self._attbn1(self._attdeconv(att, x.shape)))\n",
    "        x = x * torch.sigmoid(att)\n",
    "        \n",
    "        # bottleneck\n",
    "        x = self._relu(self._botbn0(self._bot1x1_0(x)))\n",
    "        x = self._relu(self._botbn1(self._bot3x3(x)))\n",
    "        feature = self._relu(self._botbn2(self._bot1x1_1(x)))\n",
    "        #print(feature.shape)\n",
    "        # classifier\n",
    "        x = self._globalavgpool(feature)\n",
    "        x = self._shallow_classifier(x).squeeze()\n",
    "        \n",
    "        return x, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = torch.randn(1, 64, 112, 112)\n",
    "sample2 = torch.randn(1, 128, 56, 56)\n",
    "sample3 = torch.randn(1, 256, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_module1 = SCAN(channels=64, bottle_stride=(2,2,2))\n",
    "scan_module2 = SCAN(channels=128, bottle_stride=(2,2,1))\n",
    "scan_module3 = SCAN(channels=256, bottle_stride=(1,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = scan_module1(sample1)\n",
    "result2 = scan_module2(sample2)\n",
    "result3 = scan_module3(sample3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation                                            OPS         \n",
      "---------------------------------------------------  ----------  \n",
      "SCAN/Conv2d[_attconv]/onnx::Conv                     115655680   \n",
      "SCAN/BatchNorm2d[_attbn0]/onnx::BatchNormalization   100352      \n",
      "SCAN/ReLU[_relu]/onnx::Relu                          100352      \n",
      "SCAN/BatchNorm2d[_attbn1]/onnx::BatchNormalization   401408      \n",
      "SCAN/ReLU[_relu]/onnx::Relu                          401408      \n",
      "SCAN/Conv2d[_bot1x1_0]/onnx::Conv                    51380224    \n",
      "SCAN/BatchNorm2d[_botbn0]/onnx::BatchNormalization   401408      \n",
      "SCAN/ReLU[_relu]/onnx::Relu                          401408      \n",
      "SCAN/Conv2d[_bot3x3]/onnx::Conv                      115605504   \n",
      "SCAN/BatchNorm2d[_botbn1]/onnx::BatchNormalization   100352      \n",
      "SCAN/ReLU[_relu]/onnx::Relu                          100352      \n",
      "SCAN/Conv2d[_bot1x1_1]/onnx::Conv                    25690112    \n",
      "SCAN/BatchNorm2d[_botbn2]/onnx::BatchNormalization   200704      \n",
      "SCAN/ReLU[_relu]/onnx::Relu                          200704      \n",
      "SCAN/Conv2d[_shallow_classifier]/onnx::Conv          51200       \n",
      "--------------------------------------------------   ---------   \n",
      "Input size: (1, 256, 28, 28)\n",
      "310,791,168 FLOPs or approx. 0.31 GFLOPs\n",
      "flops: 310.7912M, params: 2.0205M\n"
     ]
    }
   ],
   "source": [
    "from pthflops import count_ops\n",
    "\n",
    "def counter(model, sample, verbose=True):\n",
    "    model = model.eval()\n",
    "    \n",
    "    M = 1000000\n",
    "    params_num = 0\n",
    "    for params in model.parameters():\n",
    "        params_num += params.view(-1).shape[0]    \n",
    "\n",
    "    flops = count_ops(model, sample, verbose=verbose)\n",
    "    print(\"flops: {:.4f}M, params: {:.4f}M\".format(flops/1000000, params_num/1000000))\n",
    "    \n",
    "    return params, flops\n",
    "\n",
    "params, flops = counter(scan_module3, sample3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EPE(nn.Module):\n",
    "    \"\"\"\n",
    "    EPE Module\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, stride=(1,1,1), final_channels=512, expansion=2, num_class=100):\n",
    "        super(EPE, self).__init__()\n",
    "        \n",
    "        # activation func\n",
    "        self._relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # expansion module\n",
    "        mid_channels = channels * expansion\n",
    "        self._expansion_conv = nn.Conv2d(channels, mid_channels, kernel_size=1, stride=stride[0], bias=False)\n",
    "        self._bn0 = nn.BatchNorm2d(mid_channels)\n",
    "        \n",
    "        # conv module\n",
    "        self._depthwise_conv = nn.Conv2d(mid_channels, mid_channels, kernel_size=3, stride=stride[1], padding=1, bias=False, groups=channels)\n",
    "        self._bn1 = nn.BatchNorm2d(mid_channels)\n",
    "        \n",
    "        self._projection_conv = nn.Conv2d(mid_channels, final_channels, kernel_size=1, stride=stride[2], bias=False)\n",
    "        self._bn2 = nn.BatchNorm2d(final_channels)\n",
    "        \n",
    "        # classifier module\n",
    "        self._globalavgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self._shallow_classifier = nn.Conv2d(final_channels, num_class, kernel_size=1, stride=1, bias=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # conv\n",
    "        x = self._relu(self._bn0(self._expansion_conv(x)))\n",
    "        x = self._relu(self._bn1(self._depthwise_conv(x)))\n",
    "        x = self._relu(self._bn2(self._projection_conv(x)))\n",
    "\n",
    "        # classifier\n",
    "        x = self._globalavgpool(x)\n",
    "        x = self._shallow_classifier(x).squeeze()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "epe_module1 = EPE(64, stride=(2,2,2))\n",
    "epe_module2 = EPE(128, stride=(2,2,1))\n",
    "epe_module3 = EPE(256, stride=(1,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation                                        OPS         \n",
      "-----------------------------------------------  ----------  \n",
      "EPE/Conv2d[_expansion_conv]/onnx::Conv           103161856   \n",
      "EPE/BatchNorm2d[_bn0]/onnx::BatchNormalization   802816      \n",
      "EPE/ReLU[_relu]/onnx::Relu                       802816      \n",
      "EPE/Conv2d[_depthwise_conv]/onnx::Conv           1806336     \n",
      "EPE/BatchNorm2d[_bn1]/onnx::BatchNormalization   200704      \n",
      "EPE/ReLU[_relu]/onnx::Relu                       200704      \n",
      "EPE/Conv2d[_projection_conv]/onnx::Conv          51380224    \n",
      "EPE/BatchNorm2d[_bn2]/onnx::BatchNormalization   200704      \n",
      "EPE/ReLU[_relu]/onnx::Relu                       200704      \n",
      "EPE/Conv2d[_shallow_classifier]/onnx::Conv       51200       \n",
      "----------------------------------------------   ---------   \n",
      "Input size: (1, 256, 28, 28)\n",
      "158,808,064 FLOPs or approx. 0.16 GFLOPs\n",
      "flops: 158.8081M, params: 0.4568M\n"
     ]
    }
   ],
   "source": [
    "params, flops = counter(epe_module3, sample3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.randn(1,3,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation                                                                                                OPS       \n",
      "-------------------------------------------------------------------------------------------------------  --------  \n",
      "ResNet/Conv2d[conv1]/onnx::Conv                                                                          2424832   \n",
      "ResNet/BatchNorm2d[bn1]/onnx::BatchNormalization                                                         32768     \n",
      "ResNet/ReLU[relu]/onnx::Relu                                                                             32768     \n",
      "ResNet/MaxPool2d[maxpool]/onnx::MaxPool                                                                  32768     \n",
      "ResNet/Sequential[layer1]/BasicBlock[0]/Conv2d[conv1]/onnx::Conv                                         2359296   \n",
      "ResNet/Sequential[layer1]/BasicBlock[0]/BatchNorm2d[bn1]/onnx::BatchNormalization                        8192      \n",
      "ResNet/Sequential[layer1]/BasicBlock[0]/ReLU[relu]/onnx::Relu                                            8192      \n",
      "ResNet/Sequential[layer1]/BasicBlock[0]/Conv2d[conv2]/onnx::Conv                                         2359296   \n",
      "ResNet/Sequential[layer1]/BasicBlock[0]/BatchNorm2d[bn2]/onnx::BatchNormalization                        8192      \n",
      "ResNet/Sequential[layer1]/BasicBlock[0]/onnx::Add                                                        4096      \n",
      "ResNet/Sequential[layer1]/BasicBlock[0]/ReLU[relu]/onnx::Relu                                            8192      \n",
      "ResNet/Sequential[layer1]/BasicBlock[1]/Conv2d[conv1]/onnx::Conv                                         2359296   \n",
      "ResNet/Sequential[layer1]/BasicBlock[1]/BatchNorm2d[bn1]/onnx::BatchNormalization                        8192      \n",
      "ResNet/Sequential[layer1]/BasicBlock[1]/ReLU[relu]/onnx::Relu                                            8192      \n",
      "ResNet/Sequential[layer1]/BasicBlock[1]/Conv2d[conv2]/onnx::Conv                                         2359296   \n",
      "ResNet/Sequential[layer1]/BasicBlock[1]/BatchNorm2d[bn2]/onnx::BatchNormalization                        8192      \n",
      "ResNet/Sequential[layer1]/BasicBlock[1]/onnx::Add                                                        4096      \n",
      "ResNet/Sequential[layer1]/BasicBlock[1]/ReLU[relu]/onnx::Relu                                            8192      \n",
      "ResNet/Sequential[layer2]/BasicBlock[0]/Conv2d[conv1]/onnx::Conv                                         1179648   \n",
      "ResNet/Sequential[layer2]/BasicBlock[0]/BatchNorm2d[bn1]/onnx::BatchNormalization                        4096      \n",
      "ResNet/Sequential[layer2]/BasicBlock[0]/ReLU[relu]/onnx::Relu                                            4096      \n",
      "ResNet/Sequential[layer2]/BasicBlock[0]/Conv2d[conv2]/onnx::Conv                                         2359296   \n",
      "ResNet/Sequential[layer2]/BasicBlock[0]/BatchNorm2d[bn2]/onnx::BatchNormalization                        4096      \n",
      "ResNet/Sequential[layer2]/BasicBlock[0]/Sequential[downsample]/Conv2d[0]/onnx::Conv                      131072    \n",
      "ResNet/Sequential[layer2]/BasicBlock[0]/Sequential[downsample]/BatchNorm2d[1]/onnx::BatchNormalization   4096      \n",
      "ResNet/Sequential[layer2]/BasicBlock[0]/onnx::Add                                                        2048      \n",
      "ResNet/Sequential[layer2]/BasicBlock[0]/ReLU[relu]/onnx::Relu                                            4096      \n",
      "ResNet/Sequential[layer2]/BasicBlock[1]/Conv2d[conv1]/onnx::Conv                                         2359296   \n",
      "ResNet/Sequential[layer2]/BasicBlock[1]/BatchNorm2d[bn1]/onnx::BatchNormalization                        4096      \n",
      "ResNet/Sequential[layer2]/BasicBlock[1]/ReLU[relu]/onnx::Relu                                            4096      \n",
      "ResNet/Sequential[layer2]/BasicBlock[1]/Conv2d[conv2]/onnx::Conv                                         2359296   \n",
      "ResNet/Sequential[layer2]/BasicBlock[1]/BatchNorm2d[bn2]/onnx::BatchNormalization                        4096      \n",
      "ResNet/Sequential[layer2]/BasicBlock[1]/onnx::Add                                                        2048      \n",
      "ResNet/Sequential[layer2]/BasicBlock[1]/ReLU[relu]/onnx::Relu                                            4096      \n",
      "ResNet/Sequential[layer3]/BasicBlock[0]/Conv2d[conv1]/onnx::Conv                                         1179648   \n",
      "ResNet/Sequential[layer3]/BasicBlock[0]/BatchNorm2d[bn1]/onnx::BatchNormalization                        2048      \n",
      "ResNet/Sequential[layer3]/BasicBlock[0]/ReLU[relu]/onnx::Relu                                            2048      \n",
      "ResNet/Sequential[layer3]/BasicBlock[0]/Conv2d[conv2]/onnx::Conv                                         2359296   \n",
      "ResNet/Sequential[layer3]/BasicBlock[0]/BatchNorm2d[bn2]/onnx::BatchNormalization                        2048      \n",
      "ResNet/Sequential[layer3]/BasicBlock[0]/Sequential[downsample]/Conv2d[0]/onnx::Conv                      131072    \n",
      "ResNet/Sequential[layer3]/BasicBlock[0]/Sequential[downsample]/BatchNorm2d[1]/onnx::BatchNormalization   2048      \n",
      "ResNet/Sequential[layer3]/BasicBlock[0]/onnx::Add                                                        1024      \n",
      "ResNet/Sequential[layer3]/BasicBlock[0]/ReLU[relu]/onnx::Relu                                            2048      \n",
      "ResNet/Sequential[layer3]/BasicBlock[1]/Conv2d[conv1]/onnx::Conv                                         2359296   \n",
      "ResNet/Sequential[layer3]/BasicBlock[1]/BatchNorm2d[bn1]/onnx::BatchNormalization                        2048      \n",
      "ResNet/Sequential[layer3]/BasicBlock[1]/ReLU[relu]/onnx::Relu                                            2048      \n",
      "ResNet/Sequential[layer3]/BasicBlock[1]/Conv2d[conv2]/onnx::Conv                                         2359296   \n",
      "ResNet/Sequential[layer3]/BasicBlock[1]/BatchNorm2d[bn2]/onnx::BatchNormalization                        2048      \n",
      "ResNet/Sequential[layer3]/BasicBlock[1]/onnx::Add                                                        1024      \n",
      "ResNet/Sequential[layer3]/BasicBlock[1]/ReLU[relu]/onnx::Relu                                            2048      \n",
      "ResNet/Sequential[layer4]/BasicBlock[0]/Conv2d[conv1]/onnx::Conv                                         1179648   \n",
      "ResNet/Sequential[layer4]/BasicBlock[0]/BatchNorm2d[bn1]/onnx::BatchNormalization                        1024      \n",
      "ResNet/Sequential[layer4]/BasicBlock[0]/ReLU[relu]/onnx::Relu                                            1024      \n",
      "ResNet/Sequential[layer4]/BasicBlock[0]/Conv2d[conv2]/onnx::Conv                                         2359296   \n",
      "ResNet/Sequential[layer4]/BasicBlock[0]/BatchNorm2d[bn2]/onnx::BatchNormalization                        1024      \n",
      "ResNet/Sequential[layer4]/BasicBlock[0]/Sequential[downsample]/Conv2d[0]/onnx::Conv                      131072    \n",
      "ResNet/Sequential[layer4]/BasicBlock[0]/Sequential[downsample]/BatchNorm2d[1]/onnx::BatchNormalization   1024      \n",
      "ResNet/Sequential[layer4]/BasicBlock[0]/onnx::Add                                                        512       \n",
      "ResNet/Sequential[layer4]/BasicBlock[0]/ReLU[relu]/onnx::Relu                                            1024      \n",
      "ResNet/Sequential[layer4]/BasicBlock[1]/Conv2d[conv1]/onnx::Conv                                         2359296   \n",
      "ResNet/Sequential[layer4]/BasicBlock[1]/BatchNorm2d[bn1]/onnx::BatchNormalization                        1024      \n",
      "ResNet/Sequential[layer4]/BasicBlock[1]/ReLU[relu]/onnx::Relu                                            1024      \n",
      "ResNet/Sequential[layer4]/BasicBlock[1]/Conv2d[conv2]/onnx::Conv                                         2359296   \n",
      "ResNet/Sequential[layer4]/BasicBlock[1]/BatchNorm2d[bn2]/onnx::BatchNormalization                        1024      \n",
      "ResNet/Sequential[layer4]/BasicBlock[1]/onnx::Add                                                        512       \n",
      "ResNet/Sequential[layer4]/BasicBlock[1]/ReLU[relu]/onnx::Relu                                            1024      \n",
      "ResNet/Linear[fc]/onnx::Gemm                                                                             512000    \n",
      "------------------------------------------------------------------------------------------------------   -------   \n",
      "Input size: (1, 3, 32, 32)\n",
      "37,783,552 FLOPs or approx. 0.04 GFLOPs\n",
      "flops: 37.7836M, params: 11.6895M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([-2.4426e-02,  2.3967e-02, -2.9111e-02, -2.1427e-02,  4.3984e-02,\n",
       "          3.0813e-02,  1.2565e-02,  8.0713e-03, -1.9495e-02,  2.4364e-02,\n",
       "          4.3021e-03,  1.5280e-02, -2.3674e-02,  6.3198e-03,  4.2103e-02,\n",
       "         -4.1981e-02,  3.6257e-02,  3.5632e-02,  3.1763e-03,  3.1044e-02,\n",
       "         -1.8174e-02, -1.3629e-02, -2.9928e-02, -2.2692e-02, -2.7269e-03,\n",
       "          3.6816e-02,  2.3959e-02,  4.3799e-02,  2.9688e-02,  3.7647e-02,\n",
       "          1.5104e-02, -7.5375e-03,  1.3225e-02,  5.7249e-03, -1.1666e-02,\n",
       "         -2.9981e-02,  3.2902e-02, -3.2995e-02, -3.0110e-02,  1.1996e-02,\n",
       "          1.6513e-02,  3.5449e-02,  3.8253e-02, -3.9126e-04,  5.3069e-03,\n",
       "         -3.0493e-02,  3.5185e-02, -1.2021e-02,  4.3209e-03, -1.9483e-02,\n",
       "          2.4133e-02, -3.6570e-02,  1.1128e-02,  7.5300e-03, -1.9603e-02,\n",
       "         -3.9263e-02,  2.1353e-03, -2.6687e-02,  3.1525e-02,  1.4052e-02,\n",
       "         -7.3651e-03,  3.4925e-02,  9.1222e-03, -2.0324e-02,  1.2228e-02,\n",
       "          5.3830e-03,  2.6087e-02,  3.1003e-02, -2.5257e-02, -6.4925e-03,\n",
       "         -1.6680e-02, -1.7757e-02,  1.9089e-02, -1.7010e-02, -3.4483e-02,\n",
       "          9.3466e-03,  2.7972e-02,  1.3759e-02, -1.0631e-02, -4.1663e-02,\n",
       "         -1.9593e-03, -3.5334e-02, -9.1763e-03, -3.6587e-02,  1.0759e-02,\n",
       "          1.3404e-02,  2.0603e-02, -1.1921e-02,  3.4068e-02,  2.7685e-03,\n",
       "         -3.8430e-02, -3.3681e-02,  9.8666e-03,  7.8770e-03, -8.9256e-03,\n",
       "          4.1156e-02,  2.7299e-02,  1.5300e-02, -1.6916e-03, -2.2563e-02,\n",
       "         -2.5295e-02, -4.0495e-02,  1.6603e-02,  3.3286e-02,  1.5505e-03,\n",
       "         -4.0782e-02,  3.3583e-02,  1.2214e-03, -8.6805e-03, -1.9611e-02,\n",
       "          1.6296e-02, -6.1005e-03, -2.8648e-02,  2.3592e-02, -4.3709e-02,\n",
       "         -3.9269e-03, -1.6032e-03,  1.3067e-02, -1.3692e-02,  1.6461e-02,\n",
       "         -1.3256e-02, -1.1524e-02, -5.9259e-03,  3.9758e-02,  3.6484e-02,\n",
       "          2.5957e-02, -2.0662e-02,  8.2472e-03,  9.4567e-03, -1.1994e-02,\n",
       "         -2.7277e-03,  1.9152e-02,  3.8406e-02,  1.3250e-02, -4.3160e-02,\n",
       "          1.0167e-03, -8.9402e-03, -2.7558e-02, -1.4646e-02,  1.5991e-03,\n",
       "         -2.0261e-02, -2.1772e-02,  4.3174e-02,  1.8296e-02, -2.8129e-02,\n",
       "         -3.5164e-04, -3.2314e-03,  2.8450e-02, -4.4164e-02,  4.2365e-02,\n",
       "          4.0572e-02, -7.1891e-03, -1.7374e-02,  3.4936e-02,  2.8778e-02,\n",
       "         -1.6572e-03, -4.1607e-02,  2.9126e-03,  1.6723e-02,  3.8669e-02,\n",
       "          1.4480e-02, -4.0667e-02,  4.1731e-02, -4.0080e-02, -3.6642e-03,\n",
       "          2.8121e-02,  3.3284e-02,  1.0983e-02,  5.7607e-03, -3.9871e-02,\n",
       "          3.6484e-02, -1.5442e-02, -2.7927e-02,  5.2356e-03,  6.8359e-03,\n",
       "          1.2093e-02, -5.6871e-03, -1.2267e-02, -4.1124e-03,  9.6585e-03,\n",
       "          1.8957e-02, -2.3424e-02, -2.3982e-02,  1.9981e-03, -3.5020e-02,\n",
       "         -1.8835e-02,  2.1284e-02,  3.3731e-02, -2.7081e-02,  3.7623e-02,\n",
       "          1.0474e-03, -4.8471e-04,  2.0121e-02, -1.9401e-02,  3.6357e-02,\n",
       "          3.2285e-02,  3.4063e-02, -3.6430e-02,  4.1635e-02, -2.4343e-03,\n",
       "         -1.7933e-02, -1.1683e-02,  3.4019e-02,  2.5909e-02,  9.6723e-03,\n",
       "         -4.3275e-02,  4.2995e-02,  1.6779e-02,  2.1097e-02,  3.4348e-02,\n",
       "          3.0722e-02, -2.9632e-02,  3.0869e-02, -4.0575e-02, -3.0121e-02,\n",
       "          2.5123e-02, -2.1214e-02, -5.4623e-03, -4.3437e-02,  3.1907e-02,\n",
       "         -2.6856e-02,  3.9655e-02, -2.3465e-02,  2.1501e-02, -4.0178e-02,\n",
       "          3.3199e-02, -1.0546e-02,  1.9284e-02, -3.4230e-02, -2.3655e-02,\n",
       "         -3.5466e-02,  2.3513e-02,  2.3043e-02,  3.6889e-02, -1.8313e-02,\n",
       "          2.4337e-02, -3.2661e-02,  3.1257e-02,  3.5313e-03, -3.2120e-02,\n",
       "         -3.3215e-03, -6.0210e-03,  2.3445e-02,  4.9511e-04,  1.1784e-02,\n",
       "          2.6653e-02, -2.9794e-02,  1.8026e-04, -2.8032e-02, -2.9733e-02,\n",
       "          3.6493e-04,  2.1413e-03,  3.6120e-02,  5.7899e-03, -3.9654e-02,\n",
       "         -9.9160e-03,  3.8905e-02,  3.6627e-02,  3.2239e-03,  2.0778e-02,\n",
       "         -1.1775e-02, -3.7930e-02,  2.7832e-02, -1.0708e-02,  2.2127e-02,\n",
       "          2.3472e-02, -1.3800e-02,  7.9272e-03,  1.0902e-02,  4.2072e-02,\n",
       "         -3.8570e-03, -3.2924e-03,  2.2404e-02, -1.4051e-03,  2.7653e-02,\n",
       "         -3.1173e-02,  4.0042e-02,  3.0796e-02, -2.3564e-02,  1.4312e-02,\n",
       "          4.0380e-02,  3.5876e-02,  2.1126e-02,  1.4827e-02,  7.1549e-03,\n",
       "          3.2584e-02, -2.3206e-02,  1.5348e-03, -2.6054e-02,  3.1845e-02,\n",
       "         -2.1270e-02, -1.0537e-02, -1.3136e-02, -1.1249e-02,  2.3715e-02,\n",
       "          3.9124e-02,  1.4790e-02,  4.0763e-04,  6.6326e-03, -2.4878e-02,\n",
       "          1.1232e-02, -2.3072e-02, -1.0132e-02,  4.4045e-02, -2.4204e-02,\n",
       "          2.3059e-02, -6.3220e-03,  1.5067e-02, -4.1953e-02,  3.3068e-02,\n",
       "         -1.0526e-02,  3.6355e-02, -6.5621e-03, -3.3978e-02, -2.7189e-02,\n",
       "          2.5128e-03, -9.9017e-03,  2.3890e-02,  2.9020e-03,  2.3016e-02,\n",
       "         -2.4728e-02, -1.2176e-02,  1.3858e-02,  2.1662e-02,  3.0680e-02,\n",
       "          1.0340e-03, -2.5310e-02, -9.8383e-03,  1.4284e-03, -2.3169e-02,\n",
       "         -1.9851e-02, -7.3326e-03,  2.0985e-02, -1.1437e-02,  5.7991e-03,\n",
       "         -2.9549e-02,  1.0614e-02, -4.2498e-02,  3.2766e-02,  3.3738e-02,\n",
       "          1.8511e-02,  1.9050e-02,  4.3535e-02, -4.0788e-02, -1.8632e-02,\n",
       "         -1.7990e-02, -3.8844e-02, -2.9102e-02, -1.0706e-02, -1.1410e-02,\n",
       "         -3.5711e-02,  4.1897e-02,  7.6236e-03, -2.4820e-02,  2.9112e-02,\n",
       "         -1.6416e-03,  3.1508e-02, -3.8839e-02, -3.4497e-02, -2.6551e-03,\n",
       "          4.1034e-02,  2.3670e-02, -2.3407e-02, -3.4896e-02,  9.3430e-03,\n",
       "          2.6457e-02, -4.3772e-02, -3.9802e-02,  1.0585e-02,  3.8585e-02,\n",
       "         -2.7834e-02,  5.5006e-03,  3.0939e-02, -3.3214e-02,  3.8225e-02,\n",
       "          4.3427e-02, -8.2297e-03,  1.7314e-02, -3.8904e-02,  4.2086e-02,\n",
       "          4.8654e-03,  2.6633e-02, -2.3816e-02,  1.4855e-02,  3.3407e-02,\n",
       "         -2.9133e-02,  1.1559e-02,  1.3843e-02, -2.2298e-02, -4.2124e-02,\n",
       "         -1.0744e-02, -9.8712e-03, -1.9812e-02,  2.7884e-02, -2.1947e-02,\n",
       "          6.3203e-03, -2.3660e-02, -2.2776e-02, -3.5945e-02, -1.7711e-02,\n",
       "          1.8228e-03,  3.9248e-02,  3.5694e-02, -7.2985e-03,  4.3737e-02,\n",
       "         -9.6457e-03, -1.8917e-02, -2.5271e-02, -6.4394e-03, -1.0627e-02,\n",
       "          3.4650e-02,  3.6877e-02, -1.7905e-02, -2.3917e-02,  2.2881e-02,\n",
       "          7.2839e-03,  3.4907e-02,  3.4134e-02,  1.5947e-02, -4.0003e-02,\n",
       "         -1.3525e-02,  2.6455e-02, -3.4791e-02,  3.3463e-02, -1.8898e-02,\n",
       "          1.2557e-02, -1.6560e-02,  3.3993e-04, -1.7604e-02, -5.3999e-03,\n",
       "         -2.6073e-04, -2.8460e-03,  3.1884e-02, -1.8776e-02, -2.0087e-02,\n",
       "          4.0383e-02,  3.2693e-02,  1.8569e-03,  6.1609e-03, -2.2580e-02,\n",
       "         -1.4818e-04,  2.1447e-02,  2.0515e-02,  2.4913e-02, -3.3753e-02,\n",
       "          2.4004e-02, -4.0462e-02, -2.1927e-02, -3.4898e-02,  6.7291e-03,\n",
       "          9.4879e-03,  3.6142e-02, -2.2436e-02,  2.8527e-02, -6.7068e-03,\n",
       "         -3.8087e-02, -3.2114e-02,  4.1558e-02,  3.5601e-02, -3.1612e-02,\n",
       "          4.1908e-03,  3.5318e-03,  2.6161e-02, -6.9907e-03, -3.5182e-02,\n",
       "          4.6259e-03,  2.1729e-02,  8.2416e-03,  2.4697e-02, -3.3569e-02,\n",
       "         -2.1738e-02,  3.6013e-02,  2.2969e-02,  5.7367e-03,  2.9783e-02,\n",
       "          3.7160e-02,  1.3792e-02, -2.9762e-02,  1.1923e-03,  1.6991e-02,\n",
       "          1.1678e-02,  2.1187e-02, -3.2802e-02,  7.8083e-03, -4.3268e-02,\n",
       "         -3.4103e-02, -2.7479e-03,  1.3745e-03,  3.8650e-02,  3.6313e-02,\n",
       "          1.7607e-02,  4.0960e-02,  1.1820e-02,  5.6994e-03, -2.8291e-02,\n",
       "         -3.5759e-02,  3.0767e-02, -8.1410e-03, -2.1564e-02, -3.4178e-02,\n",
       "         -2.9401e-03,  2.3037e-02,  5.8325e-03,  1.1903e-02,  1.7661e-03,\n",
       "         -3.6109e-02,  4.0907e-02, -1.9221e-02, -1.3418e-02,  4.3955e-02,\n",
       "          1.4127e-02,  9.5959e-03,  2.3974e-02,  2.7927e-02,  1.0675e-02,\n",
       "          2.5263e-02,  2.8365e-02, -6.1476e-03,  2.5608e-02,  1.2421e-02,\n",
       "          3.0927e-02, -1.1799e-02, -1.8866e-02,  3.9833e-02, -2.5778e-02,\n",
       "          4.2551e-02, -3.2240e-02,  1.6398e-02,  1.9164e-03, -2.1005e-02,\n",
       "         -2.4102e-02, -2.2583e-02,  3.1349e-02,  2.3710e-02, -9.4726e-03,\n",
       "          4.3884e-02,  4.0759e-02, -3.5157e-02,  4.1193e-04,  7.6542e-03,\n",
       "         -2.3362e-02,  3.3990e-02,  2.9579e-02,  1.5392e-02, -2.0951e-02,\n",
       "         -3.4359e-03,  6.1389e-03,  9.6782e-03,  1.7727e-02,  5.5415e-04,\n",
       "         -3.3315e-02,  2.7280e-02, -1.5841e-02,  1.2465e-02, -2.1869e-02,\n",
       "         -1.4543e-02, -4.3138e-02,  3.8384e-02,  9.3610e-03, -3.4449e-02,\n",
       "          1.4860e-03, -1.1497e-02,  3.3632e-02,  3.2569e-02, -2.4589e-02,\n",
       "          4.4174e-02,  1.0821e-02, -4.4999e-03, -1.7064e-02,  2.9108e-02,\n",
       "         -3.2223e-02, -2.4537e-02, -1.2467e-02, -2.2290e-02, -3.7307e-02,\n",
       "          2.3230e-02, -2.4109e-02, -2.7072e-02, -1.1250e-02, -3.8543e-02,\n",
       "          2.5271e-03,  3.1668e-02,  3.9057e-02,  4.1248e-02, -2.4921e-02,\n",
       "         -2.5673e-02,  2.1552e-02,  2.2210e-02, -3.6935e-02,  1.4106e-02,\n",
       "         -1.7457e-02,  1.1537e-02, -3.9078e-03,  1.9041e-02,  3.7699e-02,\n",
       "         -3.0214e-03,  2.8776e-03, -1.7475e-02,  1.6509e-02,  3.5345e-02,\n",
       "          1.6446e-04, -3.8714e-02, -9.3103e-03, -1.9262e-04,  3.3796e-02,\n",
       "          8.0862e-03,  2.9501e-02, -2.8614e-02, -2.9694e-02,  2.4235e-02,\n",
       "          1.3525e-02,  3.8697e-02,  6.0392e-03,  9.7262e-03, -1.2652e-02,\n",
       "         -1.1493e-03, -2.7772e-02,  1.9968e-02, -2.5766e-02, -7.9873e-03,\n",
       "          2.7243e-02,  2.1363e-02,  9.7868e-03, -3.0100e-02, -3.8009e-02,\n",
       "         -3.8166e-02, -3.7612e-02,  7.3510e-03, -2.0777e-03, -3.5136e-02,\n",
       "         -2.7239e-02, -2.5425e-02,  9.9643e-03,  3.9706e-02,  4.1965e-02,\n",
       "         -6.2150e-03, -3.7780e-02,  1.0220e-02,  3.3546e-02,  1.4656e-02,\n",
       "          2.4136e-02,  3.9002e-02, -3.8078e-02,  4.1537e-02, -2.6737e-02,\n",
       "         -1.5778e-02,  4.3225e-03, -5.2976e-03, -1.6470e-02, -3.6144e-02,\n",
       "          8.2038e-03, -2.2349e-02, -1.4650e-02,  2.5074e-02,  1.6957e-02,\n",
       "          2.1992e-02,  2.8128e-02, -8.2134e-03, -3.3616e-02,  2.1959e-02,\n",
       "         -3.2067e-02, -1.3913e-03,  3.5635e-03,  3.3660e-03,  2.6978e-02,\n",
       "         -2.4269e-02,  4.7663e-03,  3.2458e-02,  1.0955e-02,  7.2672e-03,\n",
       "         -3.9467e-02, -3.4629e-02, -3.7010e-02,  2.9606e-02, -3.7804e-02,\n",
       "          4.1656e-02,  9.2295e-03, -3.3263e-02, -2.1286e-02, -2.4924e-02,\n",
       "         -1.1575e-02, -2.5100e-02, -3.7159e-03,  2.7919e-02,  1.6289e-02,\n",
       "          3.7304e-02,  3.2787e-02,  2.8657e-02,  3.9651e-02, -3.9290e-03,\n",
       "         -2.2107e-02, -1.1459e-02, -4.2684e-02, -2.2707e-02, -2.1801e-02,\n",
       "          2.4818e-02,  3.0000e-02, -3.6354e-02, -2.1875e-02, -3.5343e-02,\n",
       "         -4.9936e-03, -2.4828e-02,  1.1886e-02, -4.5218e-03,  3.6041e-02,\n",
       "         -2.8900e-02,  3.5404e-02,  1.8905e-02,  1.5180e-02, -2.0901e-02,\n",
       "          2.5033e-02,  1.7618e-02, -2.4368e-02, -8.8438e-05, -3.9582e-02,\n",
       "         -1.4755e-02, -1.7450e-02, -4.0568e-02,  1.3240e-02,  3.1541e-02,\n",
       "          1.5839e-02,  6.6612e-05, -2.7154e-02, -1.7606e-03,  1.8349e-03,\n",
       "         -4.1292e-02,  3.1501e-02, -3.8442e-02,  1.1430e-02, -7.2416e-04,\n",
       "          2.8726e-02, -1.5715e-03,  6.4472e-03, -3.2378e-03,  3.6578e-03,\n",
       "         -4.1427e-02, -1.8777e-02, -3.4161e-02, -3.0871e-02,  1.4751e-02,\n",
       "          3.0149e-02,  2.8089e-02,  4.4146e-02,  1.6091e-02, -1.8634e-02,\n",
       "         -3.7804e-02,  2.9791e-03,  3.1269e-02, -1.2055e-03,  3.0652e-02,\n",
       "         -2.8775e-03,  3.9093e-03,  2.5749e-02,  8.6234e-03,  3.5567e-02,\n",
       "         -2.8278e-02,  4.0303e-02,  2.6038e-02, -6.4298e-03, -3.5630e-02,\n",
       "          2.0891e-02,  2.0135e-02, -1.8175e-02,  4.1721e-02,  2.1761e-02,\n",
       "          1.8172e-02,  4.9523e-03,  3.0350e-02, -5.1670e-03,  4.2463e-02,\n",
       "         -1.5073e-02, -2.6140e-03, -1.4380e-02,  3.1521e-02, -4.9783e-03,\n",
       "         -3.9400e-02,  4.1313e-02,  2.3536e-02, -1.9198e-03, -1.4208e-02,\n",
       "          3.6966e-02, -3.3569e-02, -4.0346e-02,  4.5866e-03, -1.1055e-02,\n",
       "         -2.8264e-03, -8.9330e-03,  3.8382e-02, -3.2170e-02,  4.0487e-02,\n",
       "         -3.1152e-03,  5.5165e-03, -3.9139e-02,  2.5181e-02,  2.8697e-02,\n",
       "          1.5914e-02,  2.4396e-03,  4.1236e-02, -3.9989e-02,  4.7327e-03,\n",
       "          8.6829e-03,  2.9623e-02,  2.8636e-02,  2.2075e-02, -3.2111e-02,\n",
       "          3.0893e-02, -6.4324e-03, -1.4758e-02, -3.0526e-02,  1.6535e-02,\n",
       "          3.8675e-02,  4.1825e-02, -2.6045e-02,  3.0318e-02,  5.2134e-03,\n",
       "          2.2362e-02,  4.9805e-03, -3.1692e-02, -1.2689e-03, -3.6116e-02,\n",
       "          3.0149e-02,  2.8251e-02,  1.0622e-02,  9.9565e-03, -1.3507e-02,\n",
       "         -3.2239e-02,  1.9343e-02,  1.9692e-02, -2.9362e-02, -5.8435e-03,\n",
       "          1.4135e-02, -2.2826e-02, -2.2039e-02,  7.3720e-03, -1.3614e-03,\n",
       "          1.9893e-02, -2.1980e-03, -4.3060e-02, -3.1524e-02, -3.0247e-03,\n",
       "          2.4664e-02,  3.0597e-02, -3.0089e-02,  3.4705e-03,  3.8405e-02,\n",
       "         -2.2976e-03, -2.1601e-02, -1.1971e-02, -3.3471e-02,  1.1370e-02,\n",
       "         -2.2216e-02,  2.9193e-02, -4.1832e-02, -3.3824e-02, -2.6710e-02,\n",
       "          4.1913e-02,  6.7731e-03, -8.1091e-03, -3.2578e-02, -7.1535e-03,\n",
       "         -4.2111e-02,  2.9308e-02,  4.2693e-02, -2.5270e-02,  2.1961e-02,\n",
       "         -1.8992e-02,  1.0600e-02,  3.4986e-02, -5.0255e-03,  5.4912e-03,\n",
       "          2.2015e-02,  3.1512e-02,  9.6080e-03,  3.3579e-02,  6.5596e-03,\n",
       "         -2.9142e-03, -2.6621e-03, -2.8278e-02,  2.7178e-02,  3.1420e-02,\n",
       "         -2.9773e-05, -9.3742e-03, -8.6132e-03,  3.7559e-02,  1.4295e-02,\n",
       "         -1.5896e-02, -1.1749e-02, -3.0764e-02,  3.2395e-02,  1.8628e-02,\n",
       "          3.5297e-02,  4.1602e-02,  1.0253e-02,  1.2635e-02,  8.8880e-03,\n",
       "          2.2082e-02, -6.0792e-03, -1.6444e-03, -2.1576e-03,  1.7643e-02,\n",
       "         -3.3895e-02, -6.0086e-03,  4.9482e-03, -1.2807e-02,  1.7725e-02,\n",
       "         -3.6968e-02, -2.9637e-02, -3.2510e-02,  1.1245e-02,  6.5987e-03,\n",
       "          3.0946e-02,  3.6740e-02, -1.4551e-02,  1.1343e-02,  3.2222e-02,\n",
       "         -3.4272e-02,  4.3467e-02, -1.6895e-02, -8.9663e-03,  4.4010e-04,\n",
       "          2.7061e-02,  1.7337e-02, -4.1854e-02,  1.6876e-02,  1.1091e-04,\n",
       "         -3.7799e-03, -1.5446e-02, -1.9004e-02, -3.2020e-02,  6.5074e-03,\n",
       "         -3.2077e-03, -1.8850e-02, -3.2748e-02, -2.1321e-02, -1.3447e-02,\n",
       "          3.0129e-02, -3.0616e-02, -3.9125e-02,  3.2217e-02, -1.5553e-02,\n",
       "          2.1555e-02, -2.7577e-02, -3.2648e-02,  1.0004e-02,  1.1076e-02,\n",
       "          2.7705e-03,  4.2559e-02, -4.2854e-03,  1.6944e-02,  3.8044e-02,\n",
       "         -3.7564e-02, -3.2332e-02, -1.5033e-02, -3.9099e-02,  1.1009e-02,\n",
       "          3.1750e-02, -1.8580e-02,  5.6728e-03,  3.1004e-02,  5.7966e-03,\n",
       "          2.6034e-02,  5.2942e-03, -2.0399e-02, -3.9910e-02, -2.5125e-02,\n",
       "         -3.0720e-02, -2.0294e-02,  2.2960e-02, -2.6981e-02, -5.5792e-03,\n",
       "          2.4873e-02, -1.8849e-02,  6.6178e-03, -1.2396e-02, -3.2051e-02,\n",
       "          1.7489e-02, -1.8284e-02, -4.9823e-03,  4.0731e-02, -1.4840e-02,\n",
       "         -2.0342e-02,  1.3651e-02,  2.9336e-02, -3.7478e-02,  1.1386e-02,\n",
       "          2.0371e-02,  8.2337e-03, -1.8596e-02,  3.6266e-02,  4.1992e-02,\n",
       "         -4.0284e-02, -2.7661e-03,  5.1808e-03,  1.9448e-02, -4.0195e-02,\n",
       "          2.1657e-02, -8.1822e-03,  2.2994e-02,  2.0916e-02,  8.9280e-03],\n",
       "        requires_grad=True), 37783552)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter(model,sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
